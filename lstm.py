# -*- coding: utf-8 -*-
"""LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12lyTgxUJTFCoi-L0cMg7BeMY3gZP67So
"""

!pip install fastai optuna

import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import torch
from torch import nn
from torch.utils.data import TensorDataset, DataLoader
from fastai.learner import Learner
from fastai.data.core import DataLoaders
from fastai.callback.tracker import EarlyStoppingCallback
import optuna
import matplotlib.pyplot as plt

# Dataset
df = pd.read_csv("/content/btcusd_1-min_data.csv")
df['Date'] = pd.to_datetime(df['Timestamp'], unit='s')
df = df.set_index('Date')[['Close']].dropna()

# Escalado
scaler = MinMaxScaler()
scaled_close = scaler.fit_transform(df[['Close']]).flatten()

# Crear secuencias
def create_sequences(data, seq_len):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(data[i+seq_len])
    return np.array(X), np.array(y)

# Modelo LSTM
class BitcoinLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, dropout):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])

# Objetivo de Optuna usando fastai
def objective(trial):
    seq_len = trial.suggest_int('seq_len', 20, 60)
    hidden_size = trial.suggest_categorical('hidden_size', [32, 64, 128])
    dropout = trial.suggest_float('dropout', 0.0, 0.4)
    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])

    X, y = create_sequences(scaled_close, seq_len)
    train_size = int(0.8 * len(X))
    X_train, X_val = X[:train_size], X[train_size:]
    y_train, y_val = y[:train_size], y[train_size:]

    # DataLoaders
    train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1),
                             torch.tensor(y_train, dtype=torch.float32).unsqueeze(1))
    val_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32).unsqueeze(-1),
                           torch.tensor(y_val, dtype=torch.float32).unsqueeze(1))
    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
    val_dl = DataLoader(val_ds, batch_size=batch_size)

    dls = DataLoaders(train_dl, val_dl)

    model = BitcoinLSTM(input_size=1, hidden_size=hidden_size, num_layers=1, dropout=dropout)

    learn = Learner(dls, model, loss_func=nn.MSELoss(), opt_func=torch.optim.Adam,
                    cbs=EarlyStoppingCallback(monitor='valid_loss', patience=3))

    learn.fit_one_cycle(10, lr_max=lr, verbose=False)

    val_loss = learn.validate()[0]
    return val_loss

# Ejecutar Optuna
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

print("üîç Mejores hiperpar√°metros encontrados:")
print(study.best_params)



import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
import torch
from torch import nn
from torch.utils.data import TensorDataset, DataLoader
from fastai.learner import Learner
from fastai.data.core import DataLoaders
from fastai.callback.tracker import EarlyStoppingCallback
from fastai.optimizer import Adam  # ‚úÖ Esta es la versi√≥n compatible
import optuna

# Dataset
df = pd.read_csv("/content/btcusd_1-min_data.csv")
df['Date'] = pd.to_datetime(df['Timestamp'], unit='s')
df = df.set_index('Date')[['Close']].dropna()

# Escalar datos
scaler = MinMaxScaler()
scaled_close = scaler.fit_transform(df[['Close']]).flatten()

# Crear secuencias
def create_sequences(data, seq_len):
    X, y = [], []
    for i in range(len(data) - seq_len):
        X.append(data[i:i+seq_len])
        y.append(data[i+seq_len])
    return np.array(X), np.array(y)

# Modelo LSTM
class BitcoinLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, dropout):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)

    def forward(self, x):
        out, _ = self.lstm(x)
        return self.fc(out[:, -1, :])

# Objetivo para Optuna
def objective(trial):
    seq_len = trial.suggest_int('seq_len', 20, 60)
    hidden_size = trial.suggest_categorical('hidden_size', [32, 64, 128])
    dropout = trial.suggest_float('dropout', 0.0, 0.4)
    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])

    X, y = create_sequences(scaled_close, seq_len)
    train_size = int(0.8 * len(X))
    X_train, X_val = X[:train_size], X[train_size:]
    y_train, y_val = y[:train_size], y[train_size:]

    # DataLoaders
    train_ds = TensorDataset(torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1),
                             torch.tensor(y_train, dtype=torch.float32).unsqueeze(1))
    val_ds = TensorDataset(torch.tensor(X_val, dtype=torch.float32).unsqueeze(-1),
                           torch.tensor(y_val, dtype=torch.float32).unsqueeze(1))
    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
    val_dl = DataLoader(val_ds, batch_size=batch_size)
    dls = DataLoaders(train_dl, val_dl)

    # Modelo
    model = BitcoinLSTM(input_size=1, hidden_size=hidden_size, num_layers=2, dropout=dropout)

    # Usamos fastai Learner

    learn = Learner(
        dls=dls,
        model=model,
        loss_func=nn.MSELoss(),
        opt_func=Adam,  # ‚úÖ FastAI's Adam
        cbs=[EarlyStoppingCallback(monitor='valid_loss', patience=3)],
        metrics=None
    )


    # Entrenamiento
    learn.fit(10, lr=lr)
    val_loss = learn.validate()[0]
    return val_loss

# Optuna
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=10)

print("‚úÖ Mejores hiperpar√°metros encontrados:")
print(study.best_params)